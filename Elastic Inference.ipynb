{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install boto3 \n",
    "\n",
    "# !pip install boto3 --upgrade\n",
    "# pip install aws-utils\n",
    "# pip install aws-python-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curl -O https://s3.amazonaws.com/model-server/inputs/kitten.jpg\n",
    "# wget https://aws-dlc-sample-models.s3.amazonaws.com/pytorch/imagenet_classes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jersey, T-shirt, tee shirt: 0.0760\n",
      "beer glass: 0.0347\n",
      "bottlecap: 0.0240\n",
      "cellular telephone, cellular phone, cellphone, cell, mobile phone: 0.0224\n",
      "drumstick: 0.0201\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "import PIL\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def get_image(filename):\n",
    "    im = Image.open(filename)\n",
    "    # ImageNet pretrained models required input images to have width/height of 224\n",
    "    # and color channels normalized according to ImageNet distribution.\n",
    "    im_process = transforms.Compose([transforms.Resize([224, 224]),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                    std=[0.229, 0.224, 0.225])])\n",
    "    im = im_process(im) # 3 x 224 x 224\n",
    "    return im.unsqueeze(0) # Add dimension to become 1 x 3 x 224 x 224\n",
    "\n",
    "im = get_image('/home/jay/Downloads/sudhanshu.jpeg')\n",
    "\n",
    "# eval() toggles inference mode\n",
    "model = torchvision.models.resnet50(pretrained=True).eval()\n",
    "# Compile model to TorchScript via tracing\n",
    "# Here want to use the first attached accelerator, so we specify ordinal 0.\n",
    "with torch.jit.optimized_execution(True):\n",
    "  # You can trace with any input\n",
    "  model = torch.jit.trace(model, im)\n",
    "\n",
    "# Serialize model\n",
    "torch.jit.save(model, 'resnet50_traced.pt')\n",
    "\n",
    "# Deserialize model\n",
    "model = torch.jit.load('resnet50_traced.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "# Perform inference. Make sure to disable autograd and use EI execution context\n",
    "with torch.no_grad():\n",
    "    with torch.jit.optimized_execution(True):\n",
    "        probs = model(im)\n",
    "\n",
    "# Torchvision implementation doesn't have Softmax as last layer.\n",
    "# Use Softmax to convert activations to range 0-1 (probabilities)\n",
    "probs = torch.nn.Softmax(dim=1)(probs)\n",
    "\n",
    "# Get top 5 predicted classes\n",
    "classes = eval(open('/home/jay/imagenet_classes.txt').read())\n",
    "pred_probs, pred_indices = torch.topk(probs, 5)\n",
    "pred_probs = pred_probs.squeeze().numpy()\n",
    "pred_indices = pred_indices.squeeze().numpy()\n",
    "\n",
    "for i in range(len(pred_indices)):\n",
    "    curr_class = classes[pred_indices[i]]\n",
    "    curr_prob = pred_probs[i]\n",
    "    print('{}: {:.4f}'.format(curr_class, curr_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
